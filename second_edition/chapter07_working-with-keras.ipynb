{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Working with Keras: A deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A spectrum of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-2.44814500e-01,  1.95648491e-01,  8.85232389e-02,\n",
       "          5.43607473e-02, -2.22861901e-01,  9.52482224e-05,\n",
       "         -5.98973781e-02,  9.95567739e-02,  2.39699185e-01,\n",
       "          2.67157137e-01,  1.50679559e-01,  1.61356777e-01,\n",
       "         -8.06093961e-02, -5.07819653e-02, -2.84701496e-01,\n",
       "          2.51277089e-01,  5.76178432e-02,  8.28215480e-03,\n",
       "         -1.72091857e-01, -3.51879001e-02,  1.20429337e-01,\n",
       "         -2.40238994e-01, -3.66129279e-02, -2.43294090e-01,\n",
       "         -1.81619883e-01,  2.50541210e-01, -4.39343154e-02,\n",
       "         -5.79226017e-03,  1.73760593e-01, -6.72916919e-02,\n",
       "          8.41319561e-04, -3.41073573e-02, -9.11162347e-02,\n",
       "          2.18197823e-01,  4.35697436e-02,  4.43299413e-02,\n",
       "         -2.55520701e-01, -7.64250904e-02,  1.05347693e-01,\n",
       "         -1.28130287e-01, -2.78969437e-01, -5.58284372e-02,\n",
       "          2.43671119e-01,  7.74833560e-03, -1.32722914e-01,\n",
       "         -4.85585630e-02,  1.90612435e-01, -2.82319367e-01,\n",
       "          2.30324209e-01,  1.52146906e-01, -2.05228180e-01,\n",
       "          1.60639584e-01,  2.04215109e-01,  2.05457509e-01,\n",
       "         -2.80098230e-01,  1.19230747e-01,  1.37471586e-01,\n",
       "          3.86945605e-02, -1.79366231e-01, -4.45187986e-02,\n",
       "          2.91436911e-01, -1.77334756e-01,  1.86606348e-01,\n",
       "          2.13008940e-01],\n",
       "        [-5.76881766e-02,  1.31988108e-01, -1.19617313e-01,\n",
       "         -1.05888009e-01, -2.19531983e-01,  2.65651584e-01,\n",
       "          2.37109005e-01,  1.19681656e-02,  6.22835755e-03,\n",
       "         -2.59980261e-01, -1.88881904e-01,  2.53121555e-01,\n",
       "          1.83013946e-01, -1.56007081e-01, -2.61355698e-01,\n",
       "          1.14276737e-01, -1.15883276e-01,  6.98727369e-03,\n",
       "         -7.15360790e-02,  2.49759495e-01, -7.77034909e-02,\n",
       "         -8.71095806e-02,  3.79050970e-02, -1.54443428e-01,\n",
       "          7.70176947e-02, -2.58633792e-02,  1.81048512e-02,\n",
       "         -1.19002596e-01, -6.14083111e-02,  1.72976196e-01,\n",
       "         -1.68866232e-01,  2.48823702e-01, -2.35176384e-01,\n",
       "          6.65086508e-02, -1.92142904e-01,  3.20996344e-02,\n",
       "         -6.49390072e-02,  6.17832243e-02,  1.42881274e-03,\n",
       "          2.58661389e-01,  1.08153790e-01, -8.57857913e-02,\n",
       "         -2.02693403e-01,  2.21832275e-01, -1.04378581e-01,\n",
       "         -3.77401412e-02,  2.34590113e-01,  2.48958707e-01,\n",
       "          1.92423433e-01,  1.84503794e-02,  2.74708986e-01,\n",
       "         -1.63348660e-01, -1.12297073e-01, -1.48149222e-01,\n",
       "         -2.26908088e-01, -6.72177672e-02,  1.70304894e-01,\n",
       "          2.24628031e-01,  2.26270795e-01,  1.82834417e-01,\n",
       "         -2.10474849e-01, -2.42378771e-01, -1.90110430e-01,\n",
       "         -2.34186888e-01],\n",
       "        [-1.07799903e-01,  1.14737570e-01, -2.83046037e-01,\n",
       "          9.16185975e-02,  1.84277862e-01,  2.65877008e-01,\n",
       "          2.54800439e-01,  1.90820426e-01,  1.98946089e-01,\n",
       "          2.25276589e-01,  7.97834098e-02, -1.01554498e-01,\n",
       "         -2.71027207e-01,  8.98332596e-02,  5.16870618e-02,\n",
       "          1.36658520e-01, -2.76601493e-01, -1.20238364e-02,\n",
       "          1.75494909e-01,  1.02260143e-01, -3.65687609e-02,\n",
       "         -1.38272464e-01, -7.03975856e-02, -1.11083671e-01,\n",
       "         -2.04961896e-02,  5.83960116e-02, -1.28073558e-01,\n",
       "         -3.46919596e-02,  5.50610125e-02, -1.52277097e-01,\n",
       "          1.42219126e-01, -2.57665604e-01,  2.83182025e-01,\n",
       "         -1.67855814e-01, -1.50342017e-01, -1.12134680e-01,\n",
       "          2.30341494e-01, -1.94343328e-02,  2.49311268e-01,\n",
       "         -6.95172250e-02,  2.61107028e-01, -5.74475974e-02,\n",
       "         -2.26435184e-01,  1.15926802e-01, -1.91451192e-01,\n",
       "         -2.76522368e-01, -2.38302201e-01, -1.64114714e-01,\n",
       "          3.15934420e-03,  3.59726548e-02,  1.76827669e-01,\n",
       "          4.95489240e-02, -2.76965022e-01, -2.46354684e-01,\n",
       "          2.13795424e-01,  1.13218367e-01, -1.56727180e-01,\n",
       "         -1.59749180e-01, -9.10897553e-02,  1.28419310e-01,\n",
       "          8.86214375e-02,  2.91637659e-01,  9.28715169e-02,\n",
       "          3.60622704e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[ 2.84181625e-01, -1.67126119e-01,  8.43841434e-02,\n",
       "         -1.83915973e-01,  2.35302240e-01,  2.68698782e-01,\n",
       "          1.19988918e-01,  2.10656792e-01, -5.16387373e-02,\n",
       "         -1.32095352e-01],\n",
       "        [ 4.03905213e-02, -1.70559883e-02,  6.13343120e-02,\n",
       "         -2.62714803e-01,  9.72284973e-02,  1.39006972e-02,\n",
       "         -5.10897189e-02, -2.48917237e-01,  1.14370733e-01,\n",
       "          2.10318148e-01],\n",
       "        [ 2.84406930e-01,  1.65773630e-01, -9.79844928e-02,\n",
       "          2.68463880e-01, -1.14522755e-01,  8.68367851e-02,\n",
       "         -1.91817582e-01, -6.77378178e-02, -2.28421599e-01,\n",
       "          2.74633557e-01],\n",
       "        [ 8.86096358e-02,  1.82229459e-01,  2.30286628e-01,\n",
       "         -1.15206793e-01,  4.41968441e-05, -3.99520993e-02,\n",
       "          1.84219092e-01, -6.30123317e-02, -1.52300507e-01,\n",
       "         -1.56849205e-01],\n",
       "        [-1.63931325e-01,  4.77435291e-02, -1.61800683e-02,\n",
       "         -1.97584480e-01, -1.61658809e-01, -2.13146761e-01,\n",
       "          2.60290891e-01, -1.63008094e-01,  2.30709463e-01,\n",
       "         -7.65019506e-02],\n",
       "        [ 1.39460772e-01,  1.08404458e-01, -3.38144004e-02,\n",
       "          2.25170225e-01,  7.05148876e-02, -6.17686659e-02,\n",
       "         -1.60300553e-01, -9.69948024e-02,  1.38724238e-01,\n",
       "         -8.91997218e-02],\n",
       "        [ 1.24062806e-01,  1.26839727e-01, -2.07806140e-01,\n",
       "          1.84283257e-01, -2.19193578e-01, -1.01114720e-01,\n",
       "          1.44321024e-01, -2.49542028e-01,  1.16595477e-01,\n",
       "         -2.04398438e-01],\n",
       "        [-2.59768546e-01, -1.33443087e-01,  2.35297531e-01,\n",
       "         -2.16939986e-01, -2.71550179e-01, -3.41121554e-02,\n",
       "          1.12962455e-01, -1.84888810e-01, -1.35275483e-01,\n",
       "         -2.55066901e-01],\n",
       "        [ 1.26245230e-01,  8.32062066e-02,  2.07116663e-01,\n",
       "         -1.83467418e-01, -1.84125945e-01, -1.09179139e-01,\n",
       "          2.61386007e-01,  2.00926661e-02,  1.53570026e-01,\n",
       "         -1.49005175e-01],\n",
       "        [-3.23473811e-02, -3.99647355e-02, -9.43820328e-02,\n",
       "         -2.67190248e-01,  1.35959983e-02, -1.57231018e-01,\n",
       "          2.49778062e-01, -1.59612432e-01, -1.61099434e-03,\n",
       "         -7.53540099e-02],\n",
       "        [-7.12452382e-02, -1.24847457e-01,  2.65548229e-02,\n",
       "          1.06273830e-01,  2.11769968e-01,  6.24125302e-02,\n",
       "         -1.23519063e-01,  1.25311613e-01, -2.26261571e-01,\n",
       "         -1.98178038e-01],\n",
       "        [ 2.61685252e-02,  1.58488512e-01, -5.74444085e-02,\n",
       "         -2.40546316e-01,  7.39371777e-03,  1.06384009e-01,\n",
       "          9.73988771e-02,  2.48699039e-01,  1.85410738e-01,\n",
       "          9.99944806e-02],\n",
       "        [-2.68983811e-01,  5.84056377e-02, -6.86686337e-02,\n",
       "         -5.60240299e-02, -7.12758452e-02, -2.83308357e-01,\n",
       "         -2.34568954e-01, -1.61016986e-01, -1.62539184e-02,\n",
       "         -2.44573429e-01],\n",
       "        [ 2.43351847e-01, -1.74321070e-01, -5.64956516e-02,\n",
       "         -7.27361441e-02,  2.56677300e-01,  2.45661467e-01,\n",
       "         -1.34175211e-01,  1.49853587e-01, -1.08469561e-01,\n",
       "          2.30927676e-01],\n",
       "        [-1.36485875e-01, -1.84958130e-01, -2.35473230e-01,\n",
       "          9.69577432e-02,  9.94149148e-02, -1.06370017e-01,\n",
       "         -1.95477605e-01,  2.66554862e-01,  4.99235094e-02,\n",
       "          2.70126551e-01],\n",
       "        [ 3.31443250e-02,  2.19320506e-01, -2.80208886e-01,\n",
       "         -1.03622213e-01,  4.60426509e-02,  2.22558826e-01,\n",
       "          9.38619375e-02, -2.46471539e-01, -8.56806934e-02,\n",
       "         -2.24913433e-01],\n",
       "        [-3.89438868e-03,  1.67913079e-01, -4.89630252e-02,\n",
       "          1.93698853e-01, -1.01698771e-01,  5.53275645e-02,\n",
       "          1.46307737e-01,  2.78152972e-01,  2.83311993e-01,\n",
       "          2.04513252e-01],\n",
       "        [ 1.65978849e-01, -2.26107597e-01,  1.21979207e-01,\n",
       "         -2.30083182e-01, -7.60437697e-02, -1.83950067e-02,\n",
       "         -2.56991297e-01,  2.30675906e-01, -1.08781233e-01,\n",
       "         -2.80142695e-01],\n",
       "        [-2.55264461e-01,  2.35154420e-01,  1.81380719e-01,\n",
       "          1.42036974e-02, -1.50467023e-01,  9.25747454e-02,\n",
       "          9.75880325e-02, -9.37397331e-02,  3.64237726e-02,\n",
       "          6.12170696e-02],\n",
       "        [-1.87723249e-01,  4.02259827e-02,  7.34893084e-02,\n",
       "          1.51457459e-01,  2.47272760e-01,  2.16273159e-01,\n",
       "          6.61413372e-02, -1.64661735e-01,  8.70912969e-02,\n",
       "          8.19169283e-02],\n",
       "        [-1.38877407e-01,  5.03899157e-02,  1.89112127e-01,\n",
       "          2.37296909e-01, -8.11598152e-02, -5.81828952e-02,\n",
       "          2.76847869e-01, -1.99079931e-01, -4.99197841e-02,\n",
       "          2.49167085e-02],\n",
       "        [-1.22094080e-01, -1.29168734e-01,  2.37123638e-01,\n",
       "         -2.65935183e-01,  5.30237257e-02, -2.04378545e-01,\n",
       "          7.60732293e-02, -1.81490421e-01, -2.20138177e-01,\n",
       "         -2.48287320e-02],\n",
       "        [ 1.46856129e-01, -2.62457848e-01, -2.83370912e-02,\n",
       "         -2.46236637e-01,  2.44173735e-01, -2.81693399e-01,\n",
       "         -7.38774985e-02, -2.80216932e-02,  3.25376689e-02,\n",
       "          6.34758174e-02],\n",
       "        [-2.28737086e-01,  1.47727370e-01, -2.17355281e-01,\n",
       "         -2.03965172e-01, -6.60384744e-02, -2.36100554e-02,\n",
       "         -2.04199255e-01, -2.71224767e-01,  9.10398662e-02,\n",
       "         -2.15766668e-01],\n",
       "        [-2.25633055e-01, -5.53894639e-02,  1.53776556e-01,\n",
       "         -4.68570292e-02, -7.53993690e-02,  2.31040388e-01,\n",
       "          3.04702520e-02,  2.81737298e-01, -1.04563147e-01,\n",
       "         -2.19921768e-02],\n",
       "        [-9.71766859e-02,  1.06496632e-01, -8.70619565e-02,\n",
       "         -1.80697143e-01, -2.67840147e-01,  1.63868338e-01,\n",
       "          3.08674574e-02, -1.51834920e-01,  1.65474296e-01,\n",
       "          7.35870004e-03],\n",
       "        [-2.28797361e-01, -1.16072595e-01,  1.38952285e-01,\n",
       "          1.30731612e-01,  1.57492727e-01,  5.70875704e-02,\n",
       "         -4.21789289e-03,  1.44432902e-01,  1.20706081e-01,\n",
       "         -1.09072819e-01],\n",
       "        [-2.16982692e-01, -1.63978040e-01,  2.75054485e-01,\n",
       "          2.74170369e-01, -4.41733152e-02,  1.32734001e-01,\n",
       "         -5.36042601e-02, -2.16929138e-01,  6.68405294e-02,\n",
       "          1.38578415e-01],\n",
       "        [-2.29283318e-01,  4.86590862e-02, -2.62073994e-01,\n",
       "         -2.97680497e-03,  1.72991067e-01, -4.93226349e-02,\n",
       "         -2.14792117e-01, -1.05511084e-01, -1.53188899e-01,\n",
       "          2.48240530e-02],\n",
       "        [ 2.75710911e-01,  1.48470700e-02,  1.77916616e-01,\n",
       "          6.99047744e-02,  8.14226270e-02, -2.54478097e-01,\n",
       "         -1.33477449e-02, -2.37963945e-01, -2.48865038e-01,\n",
       "          2.38513976e-01],\n",
       "        [ 1.46875620e-01, -1.73372999e-01,  1.13733262e-01,\n",
       "          2.48547584e-01, -2.78109342e-01,  3.22167575e-02,\n",
       "          1.26651824e-02, -2.17275769e-01,  2.05715567e-01,\n",
       "          2.33691484e-01],\n",
       "        [ 6.28078580e-02,  1.86984420e-01,  1.34202987e-01,\n",
       "         -3.58615220e-02,  1.22285128e-01,  2.78748184e-01,\n",
       "          2.47507662e-01, -1.77996382e-01, -1.93619967e-01,\n",
       "          2.06355065e-01],\n",
       "        [ 1.50011361e-01, -8.56449753e-02, -2.30667710e-01,\n",
       "          1.64969146e-01,  5.63945770e-02,  2.80818969e-01,\n",
       "         -1.65862769e-01,  7.74553418e-03,  2.70904273e-01,\n",
       "         -1.61888301e-02],\n",
       "        [ 7.81744719e-04,  1.98447078e-01,  1.36456490e-01,\n",
       "         -4.68182713e-02, -1.78364813e-01, -2.77843088e-01,\n",
       "          7.00157583e-02,  1.20100707e-01, -7.41958618e-04,\n",
       "         -6.25573993e-02],\n",
       "        [ 9.24009681e-02, -1.84773743e-01, -1.27161518e-01,\n",
       "          2.68330485e-01,  1.97995603e-01,  2.48852462e-01,\n",
       "          1.72507405e-01,  1.30428493e-01, -2.79006422e-01,\n",
       "         -1.89633995e-01],\n",
       "        [ 2.69158632e-01,  1.81670487e-02,  3.38435173e-04,\n",
       "         -2.80792773e-01,  1.13626480e-01,  1.58009022e-01,\n",
       "         -5.60360402e-02, -1.73290044e-01,  2.67822534e-01,\n",
       "          1.05473101e-02],\n",
       "        [ 6.49759173e-03,  7.92767107e-02, -2.11291149e-01,\n",
       "         -7.67057538e-02, -2.79093444e-01, -1.76055431e-01,\n",
       "          2.63570338e-01, -1.34592250e-01,  5.14902472e-02,\n",
       "         -2.16490030e-03],\n",
       "        [ 1.53161258e-01,  1.66729093e-03,  1.19863182e-01,\n",
       "          1.02152675e-01, -1.03411138e-01,  9.35786366e-02,\n",
       "          5.97180128e-02, -1.96064040e-01, -4.65650409e-02,\n",
       "          2.08912462e-01],\n",
       "        [-9.62802768e-03,  2.42303103e-01,  1.09364599e-01,\n",
       "          1.88303441e-01,  2.25206345e-01,  3.68402004e-02,\n",
       "         -9.76064950e-02,  3.01555097e-02, -5.36544323e-02,\n",
       "          1.11062050e-01],\n",
       "        [-1.17061734e-01, -1.07011572e-01,  4.68304753e-03,\n",
       "          5.24064898e-02, -1.93279505e-01,  1.81196928e-01,\n",
       "         -2.62027174e-01, -1.80713713e-01,  1.15972936e-01,\n",
       "         -1.83155060e-01],\n",
       "        [ 9.63885486e-02, -6.80511892e-02,  6.41846955e-02,\n",
       "         -1.07858285e-01,  1.85491264e-01, -9.62799340e-02,\n",
       "          1.00174248e-01, -2.19627991e-01,  1.99339062e-01,\n",
       "          2.65330464e-01],\n",
       "        [ 1.31057471e-01, -7.56834745e-02,  3.73108089e-02,\n",
       "         -1.97934508e-01,  6.44174218e-02, -4.66904342e-02,\n",
       "         -8.59270543e-02,  1.69451535e-01,  9.61273909e-03,\n",
       "         -1.33547783e-01],\n",
       "        [-1.16637975e-01,  9.09979641e-02, -1.75707772e-01,\n",
       "         -7.46579468e-02, -1.25146851e-01, -1.99469030e-02,\n",
       "          4.96829748e-02, -8.92424136e-02, -6.39259070e-02,\n",
       "         -1.12942293e-01],\n",
       "        [-2.70559996e-01,  1.22428358e-01,  3.38902175e-02,\n",
       "         -1.75114557e-01,  3.31822038e-03,  1.43553525e-01,\n",
       "         -2.22770303e-01,  2.39974707e-01,  3.09804976e-02,\n",
       "         -1.36600405e-01],\n",
       "        [-2.32181698e-01,  1.93423837e-01,  4.84825671e-02,\n",
       "         -2.16509104e-01, -2.32881308e-03, -2.32119992e-01,\n",
       "          4.92499173e-02, -1.98647827e-01,  1.11867607e-01,\n",
       "          1.91053003e-01],\n",
       "        [ 1.72524929e-01,  2.10826695e-02,  1.42761260e-01,\n",
       "         -2.58666664e-01,  2.82883853e-01,  1.48532510e-01,\n",
       "          2.65505880e-01, -1.61597729e-02,  1.06483459e-01,\n",
       "          1.53280079e-01],\n",
       "        [ 8.13228786e-02,  5.08281291e-02, -2.84045488e-01,\n",
       "          1.87126786e-01, -1.98116004e-02, -5.36424816e-02,\n",
       "         -1.63605809e-03, -1.77252918e-01, -2.53067166e-01,\n",
       "          7.06292689e-02],\n",
       "        [-2.15139091e-01,  1.67506903e-01,  2.17832536e-01,\n",
       "          1.91475213e-01, -6.91525489e-02, -1.93786979e-01,\n",
       "          2.00763375e-01, -2.35964209e-01,  2.27257043e-01,\n",
       "          1.33548379e-01],\n",
       "        [ 2.49691695e-01, -4.26504910e-02, -8.58320147e-02,\n",
       "         -1.58897698e-01,  9.19689238e-02, -2.63584197e-01,\n",
       "          3.84722054e-02,  1.30917013e-01,  1.46989614e-01,\n",
       "          1.69247031e-01],\n",
       "        [ 2.40593761e-01,  2.50473320e-02, -5.79949766e-02,\n",
       "         -3.20951641e-02,  1.79239213e-02,  2.05892533e-01,\n",
       "         -4.96334881e-02, -1.44733861e-01,  3.60330045e-02,\n",
       "         -2.09982857e-01],\n",
       "        [-1.20234802e-01,  2.58346945e-01, -1.61817670e-02,\n",
       "         -1.73362672e-01,  1.86875463e-01,  9.47368741e-02,\n",
       "          2.29170829e-01, -1.56804338e-01, -2.36078322e-01,\n",
       "         -2.90718079e-02],\n",
       "        [ 2.21870750e-01, -1.71042293e-01, -2.41105795e-01,\n",
       "         -2.17254594e-01,  2.07741290e-01,  7.02915192e-02,\n",
       "          2.49981970e-01,  5.09309769e-03,  1.68934286e-01,\n",
       "         -5.38025647e-02],\n",
       "        [ 9.43320096e-02,  8.81554484e-02,  3.71068716e-03,\n",
       "         -2.49968499e-01,  1.64330900e-02,  1.56219482e-01,\n",
       "         -1.34967566e-02, -2.70606995e-01, -2.79050827e-01,\n",
       "         -2.71509498e-01],\n",
       "        [ 5.95817566e-02,  1.62611842e-01,  2.58762568e-01,\n",
       "          1.26382768e-01,  2.57092327e-01, -2.58112013e-01,\n",
       "         -8.08583200e-02, -2.14594483e-01, -1.11543640e-01,\n",
       "          1.31529510e-01],\n",
       "        [-2.44097188e-01, -1.84928060e-01,  2.51265854e-01,\n",
       "          1.94717675e-01, -9.29835141e-02, -8.78376663e-02,\n",
       "          2.31333047e-01, -2.10535824e-01, -4.83377576e-02,\n",
       "         -2.04117507e-01],\n",
       "        [ 7.82851875e-02, -7.95015544e-02,  2.25403875e-01,\n",
       "          1.80810988e-02, -2.12735146e-01, -8.82040560e-02,\n",
       "          2.62755185e-01, -1.80243641e-01,  2.05811143e-01,\n",
       "          2.51091033e-01],\n",
       "        [ 1.65026039e-01,  9.99769568e-03, -8.90079141e-03,\n",
       "          2.84049362e-01, -2.57251382e-01, -1.88446879e-01,\n",
       "          1.02311283e-01, -2.33616948e-01,  1.60884738e-01,\n",
       "         -1.82345420e-01],\n",
       "        [-2.16693148e-01, -2.75752217e-01,  1.16737425e-01,\n",
       "          2.41203338e-01, -3.52695882e-02,  1.38639599e-01,\n",
       "          2.74472237e-02,  2.16556042e-01, -1.85964584e-01,\n",
       "          7.64578283e-02],\n",
       "        [-2.75391608e-01, -1.51762351e-01, -8.10215920e-02,\n",
       "          2.36445457e-01, -2.41587996e-01,  9.63769555e-02,\n",
       "          2.15018451e-01,  1.03550047e-01,  7.01627135e-03,\n",
       "          1.59181744e-01],\n",
       "        [ 1.01190805e-02,  1.32985383e-01, -1.63256168e-01,\n",
       "          1.79490954e-01,  2.49514133e-01, -1.18722498e-01,\n",
       "          2.41325527e-01,  2.27076083e-01, -5.46741188e-02,\n",
       "          2.90396214e-02],\n",
       "        [-6.21029586e-02,  2.04508483e-01, -1.88258618e-01,\n",
       "         -5.77196926e-02,  2.16807276e-01, -2.06968933e-01,\n",
       "         -4.17263806e-02,  1.53019786e-01,  5.40916324e-02,\n",
       "         -8.29522312e-02],\n",
       "        [ 2.21702009e-01, -4.21711206e-02,  2.50428289e-01,\n",
       "         -2.84375161e-01,  1.60465926e-01, -7.64578581e-04,\n",
       "         -8.22894275e-02, -2.17788815e-02, -6.81926012e-02,\n",
       "         -2.32645035e-01],\n",
       "        [ 2.00128973e-01, -2.44688973e-01,  2.43454725e-01,\n",
       "          5.14341891e-02,  1.04678482e-01,  9.91078615e-02,\n",
       "          4.87778783e-02,  1.76727593e-01,  1.38063282e-01,\n",
       "         -2.33262092e-01],\n",
       "        [-2.68115938e-01,  1.25853449e-01,  1.51326030e-01,\n",
       "          1.36736810e-01,  4.89189625e-02, -8.27391297e-02,\n",
       "         -5.20331711e-02,  6.16117716e-02,  1.35861307e-01,\n",
       "          7.86453485e-03]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906 (3.54 KB)\n",
      "Trainable params: 906 (3.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906 (3.54 KB)\n",
      "Trainable params: 906 (3.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256 (1.00 KB)\n",
      "Trainable params: 256 (1.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906 (3.54 KB)\n",
      "Trainable params: 906 (3.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906 (3.54 KB)\n",
      "Trainable params: 906 (3.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 7ms/step - loss: 30.7574 - priority_loss: 0.3347 - department_loss: 30.4227 - priority_mean_absolute_error: 0.5021 - department_accuracy: 0.2203\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 35.2908 - priority_loss: 0.3382 - department_loss: 34.9526 - priority_mean_absolute_error: 0.5062 - department_accuracy: 0.2609\n",
      "40/40 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 5ms/step - loss: 42.5732 - priority_loss: 0.3382 - department_loss: 42.2351 - priority_mean_absolute_error: 0.5062 - department_accuracy: 0.2531\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 39.5991 - priority_loss: 0.3382 - department_loss: 39.2610 - priority_mean_absolute_error: 0.5062 - department_accuracy: 0.5711\n",
      "40/40 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.engine.input_layer.InputLayer at 0x152248ca0>,\n",
       " <keras.src.engine.input_layer.InputLayer at 0x152248a00>,\n",
       " <keras.src.engine.input_layer.InputLayer at 0x152248fa0>,\n",
       " <keras.src.layers.merging.concatenate.Concatenate at 0x15225b310>,\n",
       " <keras.src.layers.core.dense.Dense at 0x15225b6d0>,\n",
       " <keras.src.layers.core.dense.Dense at 0x15225ba30>,\n",
       " <keras.src.layers.core.dense.Dense at 0x15222e640>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 6ms/step - loss: 33.9639 - output_1_loss: 0.3109 - output_2_loss: 33.6530 - output_1_mean_absolute_error: 0.4800 - output_2_accuracy: 0.2594\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 48.0171 - output_1_loss: 0.3258 - output_2_loss: 47.6913 - output_1_mean_absolute_error: 0.4938 - output_2_accuracy: 0.1172\n",
      "40/40 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2961 - accuracy: 0.9118 - val_loss: 0.1557 - val_accuracy: 0.9553\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1638 - accuracy: 0.9540 - val_loss: 0.1178 - val_accuracy: 0.9682\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1414 - accuracy: 0.9621 - val_loss: 0.1156 - val_accuracy: 0.9709\n",
      "313/313 [==============================] - 0s 552us/step - loss: 0.1079 - accuracy: 0.9734\n",
      "313/313 [==============================] - 0s 547us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
